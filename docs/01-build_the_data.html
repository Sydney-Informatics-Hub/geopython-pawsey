<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>01-build_the_data.utf8.md</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="lesson.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 41px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h2 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h3 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h4 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h5 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h6 {
  padding-top: 46px;
  margin-top: -46px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Setup
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="setup.html">Setup</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Sessions
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="00-intro.html">Introduction</a>
    </li>
    <li>
      <a href="01-build_the_data.html">Building an ML dataset</a>
    </li>
    <li>
      <a href="02-explore_the_data.html">Exploring the data</a>
    </li>
    <li>
      <a href="03a-MachineLearing.html">Machine Learning</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="building-machine-learning-datasets" class="section level1">
<h1>Building Machine Learning Datasets</h1>
<p>All machine learning problems begin with a dataset, and before we can perform any kind of inference on that dataset we must create/wrangle/build it. This is often the most time-consuming and hard part of a successful machine learning workflow. There is no set procedure here, as all data is different, although there are a few simple methods we can take to make a useful dataset.</p>
<p>We will be using data from a submitted Manuscript (Butterworth and Barnett-Moore 2020) which was a finalist in the <a href="https://unearthed.solutions/u/competitions/exploresa">Unearthed, ExploreSA: Gawler Challenge</a>. You can visit the <a href="https://github.com/natbutter/gawler-exploration">original repo here</a>.</p>
<pre class="python"><code># import numpy as np
# import scipy
# from scipy import io
# import time
# import matplotlib.pyplot as plt
# import cartopy.crs as ccrs</code></pre>
</div>
<div id="goal-create-a-table-of-data-containing-targets-and-predictor-variables" class="section level1">
<h1>Goal: Create a table of data containing “targets” and “predictor variables”</h1>
<p>The targets in an ML context can be a simple binary 1 or 0, or could be some category, or the value of a particular parameter. It is the “feature” of a dataset that we want to learn something about!</p>
<p>The “predictor/feature variables” are the quatities/parameters that may have some causal relationship with the the target.</p>
<div id="step-1---what-is-our-target-variable" class="section level2">
<h2>Step 1 - What is our target variable?</h2>
<p>Are we classifying something?</p>
<div id="deposit-locations---mine-and-mineral-occurances" class="section level3">
<h3>Deposit locations - mine and mineral occurances</h3>
<p>The most important dataset for this workflow is the currently known locations of mineral occurences. Using the data we already know about these known-deposits we will build a model to predict where future occurences will be.</p>
<pre class="python"><code># For working with shapefiles (packaged is called pyshp)
import shapefile
# For working with dataframes
import pandas as pd</code></pre>
<pre class="python"><code># Set the filename
mineshape=&quot;data/MinesMinerals/mines_and_mineral_occurrences_all.shp&quot;

# Set shapefile attributes and assign
sf = shapefile.Reader(mineshape)
fields = [x[0] for x in sf.fields][1:]
records = sf.records()
shps = [s.points for s in sf.shapes()]

# Write into a dataframe for easy use
df = pd.DataFrame(columns=fields, data=records)</code></pre>
<p>View the metadata of the <a href="https://catalog.sarig.sa.gov.au/geonetwork/srv/eng/catalog.search#/metadata/a0e4b62c-ec88-44b8-a530-b4e744a6b414">South Australian all mines and mineral deposits</a> to get a better understanding for what features we could use as a target.</p>
<pre class="python"><code>#See what the dataframe looks like
print(df.columns)

#For clean printing to html drop columns that contains annoying / and \ chars.
#And set max columns
pd.options.display.max_columns = 8
df.drop(columns=[&#39;REFERENCE&#39;,&#39;O_MAP_SYMB&#39;])</code></pre>
<pre><code>Index([&#39;MINDEP_NO&#39;, &#39;DEP_NAME&#39;, &#39;REFERENCE&#39;, &#39;COMM_CODE&#39;, &#39;COMMODS&#39;,
       &#39;COMMOD_MAJ&#39;, &#39;COMM_SPECS&#39;, &#39;GCHEM_ASSC&#39;, &#39;DISC_YEAR&#39;, &#39;CLASS_CODE&#39;,
       &#39;OPER_TYPE&#39;, &#39;MAP_SYMB&#39;, &#39;STATUS_VAL&#39;, &#39;SIZE_VAL&#39;, &#39;GEOL_PROV&#39;,
       &#39;DB_RES_RVE&#39;, &#39;DB_PROD&#39;, &#39;DB_DOC_IMG&#39;, &#39;DB_EXV_IMG&#39;, &#39;DB_DEP_IMG&#39;,
       &#39;DB_DEP_FLE&#39;, &#39;COX_CLASS&#39;, &#39;REG_O_CTRL&#39;, &#39;LOC_O_CTRL&#39;, &#39;LOC_O_COM&#39;,
       &#39;O_LITH_CDE&#39;, &#39;O_LITH01&#39;, &#39;O_STRAT_NM&#39;, &#39;H_LITH_CDE&#39;, &#39;H_LITH02&#39;,
       &#39;H_STRAT_NM&#39;, &#39;H_MAP_SYMB&#39;, &#39;EASTING&#39;, &#39;NORTHING&#39;, &#39;ZONE&#39;, &#39;LONGITUDE&#39;,
       &#39;LATITUDE&#39;, &#39;SVY_METHOD&#39;, &#39;HORZ_ACC&#39;, &#39;SRCE_MAP&#39;, &#39;SRCE_CNTRE&#39;,
       &#39;COMMENTS&#39;, &#39;O_MAP_SYMB&#39;],
      dtype=&#39;object&#39;)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
MINDEP_NO
</th>
<th>
DEP_NAME
</th>
<th>
COMM_CODE
</th>
<th>
COMMODS
</th>
<th>
…
</th>
<th>
HORZ_ACC
</th>
<th>
SRCE_MAP
</th>
<th>
SRCE_CNTRE
</th>
<th>
COMMENTS
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
5219
</td>
<td>
MOUNT DAVIES NO.2A
</td>
<td>
Ni
</td>
<td>
Nickel
</td>
<td>
…
</td>
<td>
2000.0
</td>
<td>
500k meis
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<th>
1
</th>
<td>
52
</td>
<td>
ONE STONE
</td>
<td>
Ni
</td>
<td>
Nickel
</td>
<td>
…
</td>
<td>
500.0
</td>
<td>
71-385
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<th>
2
</th>
<td>
8314
</td>
<td>
HINCKLEY RANGE
</td>
<td>
Fe
</td>
<td>
Iron
</td>
<td>
…
</td>
<td>
500.0
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<th>
3
</th>
<td>
69
</td>
<td>
KALKA
</td>
<td>
V, ILM
</td>
<td>
Vanadium, Ilmenite
</td>
<td>
…
</td>
<td>
100.0
</td>
<td>
1 MILE
</td>
<td>
mgt polygon on digital map
</td>
<td>
</td>
</tr>
<tr>
<th>
4
</th>
<td>
65
</td>
<td>
ECHIDNA
</td>
<td>
Ni
</td>
<td>
Nickel
</td>
<td>
…
</td>
<td>
20.0
</td>
<td>
50K GEOL
</td>
<td>
DH ECHIDNA PROSPECT
</td>
<td>
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
8672
</th>
<td>
6937
</td>
<td>
YARINGA
</td>
<td>
QTZE
</td>
<td>
Quartzite
</td>
<td>
…
</td>
<td>
200.0
</td>
<td>
50k moc
</td>
<td>
fenced yard
</td>
<td>
</td>
</tr>
<tr>
<th>
8673
</th>
<td>
4729
</td>
<td>
WELCHS
</td>
<td>
SCHT
</td>
<td>
Schist
</td>
<td>
…
</td>
<td>
20.0
</td>
<td>
50k topo
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<th>
8674
</th>
<td>
4718
</td>
<td>
ARCADIAN
</td>
<td>
CLAY
</td>
<td>
Clay
</td>
<td>
…
</td>
<td>
5.0
</td>
<td>
Plan 1951-0327
</td>
<td>
Pit
</td>
<td>
</td>
</tr>
<tr>
<th>
8675
</th>
<td>
1436
</td>
<td>
MCDONALD
</td>
<td>
Au
</td>
<td>
Gold
</td>
<td>
…
</td>
<td>
200.0
</td>
<td>
50k moc
</td>
<td>
qz float
</td>
<td>
</td>
</tr>
<tr>
<th>
8676
</th>
<td>
8934
</td>
<td>
FAIRFIELD FARM
</td>
<td>
SAND
</td>
<td>
Sand
</td>
<td>
…
</td>
<td>
20.0
</td>
<td>
</td>
<td>
pit
</td>
<td>
</td>
</tr>
</tbody>
</table>
<p>
8677 rows × 41 columns
</p>
</div>
<pre class="python"><code>#We are building a model to target South Australia, so load in a map of it.
gawlshape=&quot;data/SA/SA_STATE_POLYGON_shp&quot;
shapeRead = shapefile.Reader(gawlshape)
shapes  = shapeRead.shapes()

#Save the boundary xy pairs in arrays we will use throughout the workflow
xval = [x[0] for x in shapes[1].points]
yval = [x[1] for x in shapes[1].points]</code></pre>
<pre class="python"><code># Subset the data, for a single Mineral target
commname=&#39;Mn&#39;

#Pull our all the occurences of the commodity and go from there
comm=df[df[&#39;COMM_CODE&#39;].str.contains(commname)]
comm=comm.reset_index(drop=True)
print(&quot;Shape of &quot;+ commname, comm.shape)

# Can make further subsets of the data here if needed
#commsig=comm[comm.SIZE_VAL!=&quot;Low Significance&quot;]
#comm=comm[comm.SIZE_VAL!=&quot;Low Significance&quot;]
#comm=comm[comm.COX_CLASS == &quot;Olympic Dam Cu-U-Au&quot;]
#comm=comm[(comm.lon&lt;max(xval)) &amp; (comm.lon&gt;min(xval)) &amp; (comm.lat&gt;min(yval)) &amp; (comm.lat&lt;max(yval))]
</code></pre>
<pre><code>Shape of Mn (115, 43)</code></pre>
<pre class="python"><code># For plotting
import matplotlib.pyplot as plt</code></pre>
<pre class="python"><code>fig = plt.figure(figsize=(8,8))
ax = plt.axes()
ax.plot(df.LONGITUDE,df.LATITUDE,&#39;b.&#39;,label=&quot;All Mineral Deposits&quot;)
ax.plot(comm.LONGITUDE,comm.LATITUDE,&#39;yx&#39;,label=commname+&quot; Deposits&quot;)

ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
#ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;o&#39;, linestyle=&#39;&#39;,markersize=5, color=&#39;y&#39;,label=commname+&quot; Deposits&quot;)

plt.xlim(128.5,141.5)
plt.ylim(-38.5,-25.5)
plt.legend(loc=3)

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_10_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
</div>
<div id="step-2---wrangle-the-geophysical-and-geological-datasets-variable-features" class="section level2">
<h2>Step 2 - Wrangle the geophysical and geological datasets (variable features)</h2>
<p>Each geophysical dataset could offer instight into various commodities. Here we load in the pre-processed datasets and prepare them for further manipulations, data-mining, and machine learning. All of the full datasets are availble from <a href="https://map.sarig.sa.gov.au/" class="uri">https://map.sarig.sa.gov.au/</a>. For this exercise we have simplified the datasets (reduced complexity and resolution). Grab full datasets from <a href="https://github.com/natbutter/gawler-exploration/tree/master/ML-DATA">https://github.com/natbutter/gawler-exploration/tree/master/ML-DATA</a></p>
<div id="resistivity-xyz-data" class="section level3">
<h3>Resistivity xyz data</h3>
<pre class="python"><code>#Read in the data
data_res=pd.read_csv(&quot;data/AusLAMP_MT_Gawler_25.xyzr&quot;,
                     sep=&#39;,&#39;,header=0,names=[&#39;lat&#39;,&#39;lon&#39;,&#39;depth&#39;,&#39;resistivity&#39;])
data_res</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
lat
</th>
<th>
lon
</th>
<th>
depth
</th>
<th>
resistivity
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
-27.363931
</td>
<td>
128.680796
</td>
<td>
-25.0
</td>
<td>
2.0007
</td>
</tr>
<tr>
<th>
1
</th>
<td>
-27.659362
</td>
<td>
128.662322
</td>
<td>
-25.0
</td>
<td>
1.9979
</td>
</tr>
<tr>
<th>
2
</th>
<td>
-27.886602
</td>
<td>
128.647965
</td>
<td>
-25.0
</td>
<td>
1.9948
</td>
</tr>
<tr>
<th>
3
</th>
<td>
-28.061394
</td>
<td>
128.636833
</td>
<td>
-25.0
</td>
<td>
1.9918
</td>
</tr>
<tr>
<th>
4
</th>
<td>
-28.195844
</td>
<td>
128.628217
</td>
<td>
-25.0
</td>
<td>
1.9885
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
11003
</th>
<td>
-35.127716
</td>
<td>
142.399588
</td>
<td>
-25.0
</td>
<td>
2.0079
</td>
</tr>
<tr>
<th>
11004
</th>
<td>
-35.230939
</td>
<td>
142.408396
</td>
<td>
-25.0
</td>
<td>
2.0084
</td>
</tr>
<tr>
<th>
11005
</th>
<td>
-35.365124
</td>
<td>
142.419903
</td>
<td>
-25.0
</td>
<td>
2.0085
</td>
</tr>
<tr>
<th>
11006
</th>
<td>
-35.539556
</td>
<td>
142.434958
</td>
<td>
-25.0
</td>
<td>
2.0076
</td>
</tr>
<tr>
<th>
11007
</th>
<td>
-35.766303
</td>
<td>
142.454694
</td>
<td>
-25.0
</td>
<td>
2.0049
</td>
</tr>
</tbody>
</table>
<p>
11008 rows × 4 columns
</p>
</div>
<pre class="python"><code>fig = plt.figure(figsize=(8,8))
ax = plt.axes()
im=ax.scatter(data_res.lon,data_res.lat,s=4,c=data_res.resistivity,cmap=&quot;jet&quot;)
ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;x&#39;, linestyle=&#39;&#39;,markersize=5, color=&#39;y&#39;,label=commname+&quot; Deposits&quot;)

plt.xlim(128.5,141.5)
plt.ylim(-38.5,-25.5)
plt.legend(loc=3)

cbaxes = fig.add_axes([0.40, 0.18, 0.2, 0.015])
cbar = plt.colorbar(im, cax = cbaxes,orientation=&quot;horizontal&quot;,extend=&#39;both&#39;)
cbar.set_label(&#39;Resistivity $\Omega$.m&#39;, labelpad=10)
cbar.ax.xaxis.set_label_position(&#39;top&#39;)

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_14_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="faults-and-dykes-vector-polylines" class="section level3">
<h3>Faults and dykes vector polylines</h3>
<pre class="python"><code># For dealing with arrays 
import numpy as np</code></pre>
<pre class="python"><code>#Get fault data neo
faultshape=&quot;data/Faults/Faults.shp&quot;
shapeRead = shapefile.Reader(faultshape)
shapes  = shapeRead.shapes()
Nshp    = len(shapes)

faultsNeo=[]
for i in range(0,Nshp):
    for j in shapes[i].points:
        faultsNeo.append([j[0],j[1]])
faultsNeo=np.array(faultsNeo)
faultsNeo</code></pre>
<pre><code>array([[133.46269605, -27.41825034],
       [133.46770683, -27.42062991],
       [133.4723624 , -27.42259841],
       ...,
       [138.44613353, -35.36560605],
       [138.44160669, -35.36672662],
       [138.43805501, -35.36793484]])</code></pre>
<pre class="python"><code>fig = plt.figure(figsize=(8,8))
ax = plt.axes()
plt.plot(faultsNeo[:,0],faultsNeo[:,1],&#39;.&#39;,markersize=0.1,label=&quot;Neoproterozoic-Faults&quot;)
ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;x&#39;, linestyle=&#39;&#39;,markersize=5, color=&#39;y&#39;,label=commname+&quot; Deposits&quot;)

plt.xlim(128.5,141.5)
plt.ylim(-38.5,-25.5)
plt.legend(loc=3)

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_18_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="netcdf-formatted-raster-grids---geophysics" class="section level3">
<h3>Netcdf formatted raster grids - geophysics</h3>
<pre class="python"><code># For timing events
import time
# For making grids and reading netcdf data
import scipy
import scipy.io</code></pre>
<pre class="python"><code>#Define a function to read the netcdf files
def readnc(filename):
    tic=time.time()
    rasterfile=filename
    data = scipy.io.netcdf_file(rasterfile,&#39;r&#39;,mmap=False)
    xdata=data.variables[&#39;lon&#39;][:]
    ydata=data.variables[&#39;lat&#39;][:]
    zdata=np.array(data.variables[&#39;Band1&#39;][:])
    data.close()
    
    toc=time.time()
    print(&quot;Loaded&quot;, rasterfile, &quot;in&quot;, f&#39;{toc-tic:.2f}s&#39;)
    print(&quot;Spacing x&quot;, f&#39;{xdata[2]-xdata[1]:.2f}&#39;, 
          &quot;y&quot;, f&#39;{ydata[2]-ydata[1]:.2f}&#39;, 
          &quot;Shape:&quot;, np.shape(zdata), &quot;Min x:&quot;, np.min(xdata), &quot;Max x:&quot;, np.max(xdata),
          &quot;Min y:&quot;, np.min(ydata), f&#39;Max y {np.max(ydata):.2f}&#39;)

    return(xdata,ydata,zdata,np.min(xdata),np.min(ydata),xdata[2]-xdata[1],ydata[2]-ydata[1])</code></pre>
<pre class="python"><code># Digital Elevation Model
x1,y1,z1,originx1,originy1,pixelx1,pixely1 = readnc(&quot;data/sa-dem.nc&quot;)
# Total Magnetic Intensity
x2,y2,z2,originx2,originy2,pixelx2,pixely2 = readnc(&quot;data/sa-mag-tmi.nc&quot;)
# Gravity
x3,y3,z3,originx3,originy3,pixelx3,pixely3 = readnc(&quot;data/sa-grav.nc&quot;)</code></pre>
<pre><code>Loaded data/sa-dem.nc in 0.02s
Spacing x 0.01 y 0.01 Shape: (1208, 1201) Min x: 129.005 Max x: 141.005 Min y: -38.065 Max y -25.99
Loaded data/sa-mag-tmi.nc in 0.01s
Spacing x 0.01 y 0.01 Shape: (1208, 1201) Min x: 129.005 Max x: 141.005 Min y: -38.065 Max y -25.99
Loaded data/sa-grav.nc in 0.01s
Spacing x 0.01 y 0.01 Shape: (1208, 1201) Min x: 129.005 Max x: 141.005 Min y: -38.065 Max y -25.99</code></pre>
<pre class="python"><code>fig = plt.figure(figsize=(8,8))
ax = plt.axes()
im=plt.pcolormesh(x1,y1,z1,cmap=&#39;Greys&#39;,shading=&#39;auto&#39;)
ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;x&#39;, linestyle=&#39;&#39;,markersize=5, color=&#39;y&#39;,label=commname+&quot; Deposits&quot;)

plt.xlim(128.5,141.5)
plt.ylim(-38.5,-25.5)
plt.legend(loc=3)

cbaxes = fig.add_axes([0.40, 0.18, 0.2, 0.015])
cbar = plt.colorbar(im, cax = cbaxes,orientation=&quot;horizontal&quot;,extend=&#39;both&#39;)
cbar.set_label(&#39;DEM (m)&#39;, labelpad=10)
cbar.ax.xaxis.set_label_position(&#39;top&#39;)

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_23_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="categorical-geology-in-vector-polygons" class="section level3">
<h3>Categorical Geology in vector polygons</h3>
<pre class="python"><code>#Archean basement geology
geolshape=shapefile.Reader(&quot;data/Archaean_Early_Mesoprterzoic_polygons_shp/geology_archaean.shp&quot;)

recsArch   = geolshape.records()
shapesArch  = geolshape.shapes()</code></pre>
<pre class="python"><code>fig = plt.figure(figsize=(8,8))
ax = plt.axes()

#Gather all the unique Major Geology unit numbers
labs=[]
for i in recsArch:
    labs.append(i[-1])

geols = list(set(labs))

# Create a unique color for each geological unit label
color = plt.cm.tab20(np.linspace(0, 1, len(geols)))
cdict={}
for i, geol in enumerate(geols):
    cdict.update({geol:color[i]})
    
#Plot each of the geology polygons
legend1=[]
for i in range(len(shapesArch)):
    boundary = shapesArch[i].points
    xs = [x for x, y in shapesArch[i].points]
    ys = [y for x, y in shapesArch[i].points]
    c = cdict[recsArch[i][-1]]
    l1 = ax.fill(xs,ys,c=c,label=recsArch[i][-1])
    legend1.append(l1)
      
#Plot the extra stuff
l2 = ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
l3 = ax.plot(comm.LONGITUDE, comm.LATITUDE, 
        marker=&#39;s&#39;, markeredgecolor=&#39;k&#39;, linestyle=&#39;&#39;,markersize=4, color=&#39;y&#39;,
        label=commname+&quot; Deposits&quot;)

#Todo: Split the legends
#ax.legend([l2,l3],[&#39;SA&#39;,commname+&quot; Deposits&quot;],loc=3)

#Legend without duplicate values
handles, labels = ax.get_legend_handles_labels()
unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]
ax.legend(*zip(*unique), bbox_to_anchor = (1.02, 1.01), ncol=3)

plt.xlim(128.5,141.5)
plt.ylim(-38.5,-25.5)
#plt.legend(loc=3) #bbox_to_anchor = (1.05, 0.6))

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_26_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
</div>
<div id="take-a-moment-to-appreciate-the-various-methods-you-have-used-just-to-load-the-data" class="section level2">
<h2>Take a moment to appreciate the various methods you have used just to load the data!</h2>
<p>Now we need to think about what we actually want to achieve? What is our goal here? This will determine what kind of data analysis/manipulation we need to make here. Consider the flow diagram for <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">choosing the right machine learning method</a>.</p>
<p>We need to assign the values of each of these geophyiscal datasets (predictor variables) to the target class (i.e. mineral deposit locations). The assumption being that the occurnece of some mineral deposit (e.g. Cu) is a function of x1, x2, x3, x4, x5, x6. Where the Resitivity is x1, the distance to a Neoprotezoic fault is x2, the value of DEM, magnetic TMI, and Gravity is x3, x4, and x5, and the geologica basement unit is x6.</p>
<pre class="python"><code># Make a Target DataFrame of the points we want to interrogate the features for
td = comm[[&#39;LONGITUDE&#39;, &#39;LATITUDE&#39;]].copy()</code></pre>
<div id="resistivity" class="section level3">
<h3>Resistivity</h3>
<pre class="python"><code># For making KD Trees
import scipy.spatial</code></pre>
<pre class="python"><code># Define a function which &quot;coregisters&quot; a point from a bunch of other points.
def coregPoint(tree,point,region,retval=&#39;index&#39;):
    &#39;&#39;&#39;
    Finds the nearest neighbour to a point from a bunch of other points
    tree - a scipy CKTree to search for the point over
    point - array([longitude,latitude])
    region - integer, same units as data
    &#39;&#39;&#39;
    dists, indexes = tree.query(point,k=1,distance_upper_bound=region) 

    if retval==&#39;index&#39;:
        return (indexes)
    elif retval==&#39;dists&#39;:
        return(dists)
    </code></pre>
<pre class="python"><code># Find the values of the resetivity grid for each lat/lon deposit location.

# Make a search-tree of the point-pairs for fast lookup of nearest matches
tree = scipy.spatial.cKDTree(np.c_[data_res.lon,data_res.lat])

# Perform the search for each point
indexes = comm.apply(
    lambda x: coregPoint(tree,np.array([x.LONGITUDE, x.LATITUDE]),1,retval=&#39;index&#39;), axis=1)</code></pre>
<pre class="python"><code>td[&#39;res&#39;] = data_res.loc[indexes].resistivity.values
td</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
LONGITUDE
</th>
<th>
LATITUDE
</th>
<th>
res
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
139.179436
</td>
<td>
-29.877637
</td>
<td>
2.2135
</td>
</tr>
<tr>
<th>
1
</th>
<td>
138.808767
</td>
<td>
-30.086296
</td>
<td>
2.3643
</td>
</tr>
<tr>
<th>
2
</th>
<td>
138.752281
</td>
<td>
-30.445684
</td>
<td>
2.1141
</td>
</tr>
<tr>
<th>
3
</th>
<td>
138.530506
</td>
<td>
-30.533225
</td>
<td>
2.2234
</td>
</tr>
<tr>
<th>
4
</th>
<td>
138.887019
</td>
<td>
-30.565479
</td>
<td>
2.1982
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
110
</th>
<td>
136.059715
</td>
<td>
-34.327929
</td>
<td>
3.4926
</td>
</tr>
<tr>
<th>
111
</th>
<td>
138.016821
</td>
<td>
-35.733084
</td>
<td>
2.0868
</td>
</tr>
<tr>
<th>
112
</th>
<td>
139.250036
</td>
<td>
-34.250155
</td>
<td>
1.9811
</td>
</tr>
<tr>
<th>
113
</th>
<td>
135.905480
</td>
<td>
-34.425866
</td>
<td>
2.7108
</td>
</tr>
<tr>
<th>
114
</th>
<td>
135.835578
</td>
<td>
-34.509779
</td>
<td>
3.1224
</td>
</tr>
</tbody>
</table>
<p>
115 rows × 3 columns
</p>
</div>
</div>
<div id="faults" class="section level3">
<h3>Faults</h3>
<pre class="python"><code>#Same for the fault data 
# but this time we get the &quot;distance to the point&quot;, rather than the value at that point.
tree = scipy.spatial.cKDTree(faultsNeo)

dists = comm.apply(
    lambda x: coregPoint(tree,np.array([x.LONGITUDE, x.LATITUDE]),100,retval=&#39;dists&#39;), axis=1)</code></pre>
<pre class="python"><code>td[&#39;faults&#39;] = dists
td</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
LONGITUDE
</th>
<th>
LATITUDE
</th>
<th>
res
</th>
<th>
faults
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
139.179436
</td>
<td>
-29.877637
</td>
<td>
2.2135
</td>
<td>
0.010691
</td>
</tr>
<tr>
<th>
1
</th>
<td>
138.808767
</td>
<td>
-30.086296
</td>
<td>
2.3643
</td>
<td>
0.103741
</td>
</tr>
<tr>
<th>
2
</th>
<td>
138.752281
</td>
<td>
-30.445684
</td>
<td>
2.1141
</td>
<td>
0.006659
</td>
</tr>
<tr>
<th>
3
</th>
<td>
138.530506
</td>
<td>
-30.533225
</td>
<td>
2.2234
</td>
<td>
0.013925
</td>
</tr>
<tr>
<th>
4
</th>
<td>
138.887019
</td>
<td>
-30.565479
</td>
<td>
2.1982
</td>
<td>
0.007356
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
110
</th>
<td>
136.059715
</td>
<td>
-34.327929
</td>
<td>
3.4926
</td>
<td>
0.526835
</td>
</tr>
<tr>
<th>
111
</th>
<td>
138.016821
</td>
<td>
-35.733084
</td>
<td>
2.0868
</td>
<td>
0.002451
</td>
</tr>
<tr>
<th>
112
</th>
<td>
139.250036
</td>
<td>
-34.250155
</td>
<td>
1.9811
</td>
<td>
0.027837
</td>
</tr>
<tr>
<th>
113
</th>
<td>
135.905480
</td>
<td>
-34.425866
</td>
<td>
2.7108
</td>
<td>
0.670323
</td>
</tr>
<tr>
<th>
114
</th>
<td>
135.835578
</td>
<td>
-34.509779
</td>
<td>
3.1224
</td>
<td>
0.776152
</td>
</tr>
</tbody>
</table>
<p>
115 rows × 4 columns
</p>
</div>
</div>
<div id="geophysics" class="section level3">
<h3>Geophysics</h3>
<pre class="python"><code># Define a function which &quot;coregisters&quot; a point within a raster.
def get_coords_at_point(originx,originy,pixelx,pixely,lon,lat):
    &#39;&#39;&#39;
    Given a point in some coordinate reference (e.g. lat/lon)
    Find the closest point to that in an array (e.g. a raster)
    and return the index location of that point in the raster.
    INPUTS
        &quot;output from &quot;gdal_data.GetGeoTransform()&quot;
    originx: first point in first axis
    originy: first point in second axis
    pixelx: difference between x points
    pixely: difference between y points
    
    lon: x/row-coordinate of interest
    lat: y/column-coordinate of interest
    
    RETURNS
    col: x index value from the raster
    row: y index value from the raster
    &#39;&#39;&#39;
    row = int((lon - originx)/pixelx)
    col = int((lat - originy)/pixely)

    return (col, row)</code></pre>
<pre class="python"><code>#Perform the search on each of our raster grids
z1list=[]
z2list=[]
z3list=[]
for lon,lat in zip(comm.LONGITUDE,comm.LATITUDE):
    
    coords = get_coords_at_point(originx1,originy1,pixelx1,pixely1,lon,lat)
    z1list.append(z1[coords])
    
    coords = get_coords_at_point(originx2,originy2,pixelx2,pixely2,lon,lat)
    z2list.append(z2[coords])
    
    coords = get_coords_at_point(originx3,originy3,pixelx3,pixely3,lon,lat)
    z3list.append(z3[coords])

#Assign the results
td[&#39;dem&#39;] = z1list
td[&#39;mag&#39;] = z2list
td[&#39;grav&#39;] = z3list</code></pre>
<pre class="python"><code>td</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
LONGITUDE
</th>
<th>
LATITUDE
</th>
<th>
res
</th>
<th>
faults
</th>
<th>
dem
</th>
<th>
mag
</th>
<th>
grav
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
139.179436
</td>
<td>
-29.877637
</td>
<td>
2.2135
</td>
<td>
0.010691
</td>
<td>
187.297424
</td>
<td>
-118.074890
</td>
<td>
1.852599
</td>
</tr>
<tr>
<th>
1
</th>
<td>
138.808767
</td>
<td>
-30.086296
</td>
<td>
2.3643
</td>
<td>
0.103741
</td>
<td>
179.499237
</td>
<td>
-209.410507
</td>
<td>
-12.722121
</td>
</tr>
<tr>
<th>
2
</th>
<td>
138.752281
</td>
<td>
-30.445684
</td>
<td>
2.1141
</td>
<td>
0.006659
</td>
<td>
398.336823
</td>
<td>
-159.566422
</td>
<td>
-6.249788
</td>
</tr>
<tr>
<th>
3
</th>
<td>
138.530506
</td>
<td>
-30.533225
</td>
<td>
2.2234
</td>
<td>
0.013925
</td>
<td>
335.983429
</td>
<td>
-131.176437
</td>
<td>
-11.665316
</td>
</tr>
<tr>
<th>
4
</th>
<td>
138.887019
</td>
<td>
-30.565479
</td>
<td>
2.1982
</td>
<td>
0.007356
</td>
<td>
554.278198
</td>
<td>
-192.363297
</td>
<td>
-1.025702
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
110
</th>
<td>
136.059715
</td>
<td>
-34.327929
</td>
<td>
3.4926
</td>
<td>
0.526835
</td>
<td>
45.866119
</td>
<td>
-244.067841
</td>
<td>
11.410070
</td>
</tr>
<tr>
<th>
111
</th>
<td>
138.016821
</td>
<td>
-35.733084
</td>
<td>
2.0868
</td>
<td>
0.002451
</td>
<td>
145.452789
</td>
<td>
-203.566940
</td>
<td>
18.458364
</td>
</tr>
<tr>
<th>
112
</th>
<td>
139.250036
</td>
<td>
-34.250155
</td>
<td>
1.9811
</td>
<td>
0.027837
</td>
<td>
276.489319
</td>
<td>
-172.889587
</td>
<td>
-1.714886
</td>
</tr>
<tr>
<th>
113
</th>
<td>
135.905480
</td>
<td>
-34.425866
</td>
<td>
2.7108
</td>
<td>
0.670323
</td>
<td>
162.431747
</td>
<td>
569.713684
</td>
<td>
15.066316
</td>
</tr>
<tr>
<th>
114
</th>
<td>
135.835578
</td>
<td>
-34.509779
</td>
<td>
3.1224
</td>
<td>
0.776152
</td>
<td>
89.274399
</td>
<td>
64.385925
</td>
<td>
24.267015
</td>
</tr>
</tbody>
</table>
<p>
115 rows × 7 columns
</p>
</div>
<pre class="python"><code># Check we got it right.
# Plot a grid, and our interrogated points

fig = plt.figure(figsize=(8,8))
ax = plt.axes()
im=plt.pcolormesh(x3,y3,z3,cmap=&#39;jet&#39;,shading=&#39;auto&#39;,vmin=min(td.grav),vmax=max(td.grav))
#ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
#ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;o&#39;, linestyle=&#39;&#39;,markersize=5, color=&#39;y&#39;,label=commname+&quot; Deposits&quot;)

ax.scatter(td.LONGITUDE, td.LATITUDE, s=20, c=td.grav,
           label=commname+&quot; Gravity&quot;,cmap=&#39;jet&#39;,vmin=min(td.grav),vmax=max(td.grav),edgecolors=&#39;white&#39;)

plt.xlim(138,140)
plt.ylim(-32,-30)
plt.legend(loc=3)

cbaxes = fig.add_axes([0.40, 0.18, 0.2, 0.015])
cbar = plt.colorbar(im, cax = cbaxes,orientation=&quot;horizontal&quot;,extend=&#39;both&#39;)
cbar.set_label(&#39;Gravity (gal)&#39;, labelpad=10)
cbar.ax.xaxis.set_label_position(&#39;top&#39;)

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_41_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="geology" class="section level3">
<h3>Geology</h3>
<pre class="python"><code># For dealing with shapefile components
from shapely.geometry import Point
from shapely.geometry import shape

#Define a function to find what polygon a point lives inside (speed imporivements can be made here)
def shapeExplore(lon,lat,shapes,recs,record):
    #&#39;record&#39; is the column index you want returned
    for i in range(len(shapes)):
        boundary = shapes[i]
        if Point((lon,lat)).within(shape(boundary)):
            return(recs[i][record])
    #if you have been through the loop with no result
    return(-9999.)</code></pre>
<pre class="python"><code>td[&#39;geol&#39;]=td.apply(lambda x: shapeExplore(x.LONGITUDE, x.LATITUDE, shapesArch,recsArch,-1), axis=1)</code></pre>
<pre class="python"><code>td</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
LONGITUDE
</th>
<th>
LATITUDE
</th>
<th>
res
</th>
<th>
faults
</th>
<th>
dem
</th>
<th>
mag
</th>
<th>
grav
</th>
<th>
geol
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
139.179436
</td>
<td>
-29.877637
</td>
<td>
2.2135
</td>
<td>
0.010691
</td>
<td>
187.297424
</td>
<td>
-118.074890
</td>
<td>
1.852599
</td>
<td>
19214
</td>
</tr>
<tr>
<th>
1
</th>
<td>
138.808767
</td>
<td>
-30.086296
</td>
<td>
2.3643
</td>
<td>
0.103741
</td>
<td>
179.499237
</td>
<td>
-209.410507
</td>
<td>
-12.722121
</td>
<td>
19218
</td>
</tr>
<tr>
<th>
2
</th>
<td>
138.752281
</td>
<td>
-30.445684
</td>
<td>
2.1141
</td>
<td>
0.006659
</td>
<td>
398.336823
</td>
<td>
-159.566422
</td>
<td>
-6.249788
</td>
<td>
19218
</td>
</tr>
<tr>
<th>
3
</th>
<td>
138.530506
</td>
<td>
-30.533225
</td>
<td>
2.2234
</td>
<td>
0.013925
</td>
<td>
335.983429
</td>
<td>
-131.176437
</td>
<td>
-11.665316
</td>
<td>
19218
</td>
</tr>
<tr>
<th>
4
</th>
<td>
138.887019
</td>
<td>
-30.565479
</td>
<td>
2.1982
</td>
<td>
0.007356
</td>
<td>
554.278198
</td>
<td>
-192.363297
</td>
<td>
-1.025702
</td>
<td>
19218
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
110
</th>
<td>
136.059715
</td>
<td>
-34.327929
</td>
<td>
3.4926
</td>
<td>
0.526835
</td>
<td>
45.866119
</td>
<td>
-244.067841
</td>
<td>
11.410070
</td>
<td>
18032
</td>
</tr>
<tr>
<th>
111
</th>
<td>
138.016821
</td>
<td>
-35.733084
</td>
<td>
2.0868
</td>
<td>
0.002451
</td>
<td>
145.452789
</td>
<td>
-203.566940
</td>
<td>
18.458364
</td>
<td>
19226
</td>
</tr>
<tr>
<th>
112
</th>
<td>
139.250036
</td>
<td>
-34.250155
</td>
<td>
1.9811
</td>
<td>
0.027837
</td>
<td>
276.489319
</td>
<td>
-172.889587
</td>
<td>
-1.714886
</td>
<td>
19220
</td>
</tr>
<tr>
<th>
113
</th>
<td>
135.905480
</td>
<td>
-34.425866
</td>
<td>
2.7108
</td>
<td>
0.670323
</td>
<td>
162.431747
</td>
<td>
569.713684
</td>
<td>
15.066316
</td>
<td>
17934
</td>
</tr>
<tr>
<th>
114
</th>
<td>
135.835578
</td>
<td>
-34.509779
</td>
<td>
3.1224
</td>
<td>
0.776152
</td>
<td>
89.274399
</td>
<td>
64.385925
</td>
<td>
24.267015
</td>
<td>
18040
</td>
</tr>
</tbody>
</table>
<p>
115 rows × 8 columns
</p>
</div>
</div>
</div>
</div>
<div id="congrats-you-now-have-an-ml-dataset-ready-to-go" class="section level1">
<h1>Congrats, you now have an ML dataset ready to go!</h1>
<p>Let’s explore the data.</p>
<pre class="python"><code># For nice easy data vis plots
import seaborn as sns</code></pre>
<pre class="python"><code># Plot historgrams and scatter plots for each combination of features.
sns.pairplot(td,palette=&quot;Set1&quot;,diag_kind=&quot;auto&quot;)</code></pre>
<pre><code>&lt;seaborn.axisgrid.PairGrid at 0x271c9d58f88&gt;</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_48_1.png" alt="" />
<p class="caption">png</p>
</div>
<pre class="python"><code>#Plot a heatmap for how correlated each of the features are
corr = td.corr() 

sns.heatmap(corr,
            cmap=plt.cm.BrBG, 
            vmin=-0.5, vmax=0.5, 
            square=True,
            xticklabels=True, yticklabels=True,
            );</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_49_0.png" alt="" />
<p class="caption">png</p>
</div>
<pre class="python"><code>#Plot a regression model through the data
sns.lmplot(
    data = td,
    x = &#39;res&#39;, y = &#39;mag&#39;
);</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_50_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="part-2---spatial-data-mining-of-datasets" class="section level1">
<h1>Part 2 - Spatial data mining of datasets</h1>
<div id="select-the-commodity-and-geophysical-features-to-use" class="section level3">
<h3>Select the commodity and geophysical features to use</h3>
<p>Edit <em>commname</em> above and turn these labels on/off as required. Generally run data mining with all labels. Then can turn these features on/off before running ML if needed.</p>
</div>
<div id="generate-the-non-deposit-dataset" class="section level3">
<h3>Generate the non-deposit dataset</h3>
<p>This step is important. There are numerous ways to generate our non-deposit set, each with different benefits and trade-offs. The randomisation of points throughout <em>some</em> domain appears to be robust. But you must think, is this domain a reasonable estimation of “background” geophysics/geology? Why are you picking these locations as non-deposits? Will they be over/under-representing actual deposits? Will they be over/under-representing actual non-deposits?</p>
<p>Change the lows, highs, and sizes as desired. And enforce the points are with some confinement area if needed. A good place to start is within the spatial extent of the known deposits/commodity.</p>
<pre class="python"><code>#Generate &quot;non-deposit&quot; points within the same spatial domains as deposits (e.g. on land, or in the gawler, or in SA).
#We may want to train and test just over the regions that the grids are valid.
#So we can crop the known deposits to the extent of the grids.

polgonshape=shapefile.Reader(&quot;SA-DATA/SA/SA_STATE_POLYGON_shp.shp&quot;)
#polgonshape=shapefile.Reader(&quot;SA-DATA/GCAS_Boundary/GCAS_Boundary.shp)
shapesPoly  = polgonshape.shapes()

#Now make a set of &quot;non-deposits&quot; using a random location within our exploration area
lats_rand=np.random.uniform(low=min(df.LATITUDE), high=max(df.LATITUDE), size=len(comm.LATITUDE))
lons_rand=np.random.uniform(low=min(df.LONGITUDE), high=max(df.LONGITUDE), size=len(comm.LONGITUDE))

#And enforce the random points are within our the shapefile boudary
#Probably more efficent ways to do this for larger datasets. Fine for now.
boundary=shapesPoly[1]
for i,_ in enumerate(lats_rand):
    while not Point((lons_rand[i],lats_rand[i])).within(shape(boundary)):
            lats_rand[i]=random.uniform(min(df.LATITUDE), max(df.LATITUDE))
            lons_rand[i]=random.uniform(min(df.LONGITUDE), max(df.LONGITUDE))
            
print(&quot;Produced&quot;, len(lats_rand),len(lons_rand), &quot;latitude-longitude pairs for non-deposits.&quot;)</code></pre>
<pre><code>---------------------------------------------------------------------------

ShapefileException                        Traceback (most recent call last)

&lt;ipython-input-86-16cc1b866924&gt; in &lt;module&gt;
      3 #So we can crop the known deposits to the extent of the grids.
      4 
----&gt; 5 polgonshape=shapefile.Reader(&quot;SA-DATA/SA/SA_STATE_POLYGON_shp.shp&quot;)
      6 #polgonshape=shapefile.Reader(&quot;SA-DATA/GCAS_Boundary/GCAS_Boundary.shp)
      7 shapesPoly  = polgonshape.shapes()


c:\users\nbutter\miniconda3\envs\geopy\lib\site-packages\shapefile.py in __init__(self, *args, **kwargs)
    806         if len(args) &gt; 0:
    807             if is_string(args[0]):
--&gt; 808                 self.load(args[0])
    809                 return
    810         # Otherwise, load from separate shp/shx/dbf args (must be file-like)


c:\users\nbutter\miniconda3\envs\geopy\lib\site-packages\shapefile.py in load(self, shapefile)
    933             self.load_dbf(shapeName)
    934             if not (self.shp or self.dbf):
--&gt; 935                 raise ShapefileException(&quot;Unable to open %s.dbf or %s.shp.&quot; % (shapeName, shapeName))
    936         if self.shp:
    937             self.__shpHeader()


ShapefileException: Unable to open SA-DATA/SA/SA_STATE_POLYGON_shp.dbf or SA-DATA/SA/SA_STATE_POLYGON_shp.shp.</code></pre>
<pre class="python"><code>#Save the SA polygon for plotting
xvalsa = [x[0] for x in shapesPoly[1].points]
yvalsa = [x[1] for x in shapesPoly[1].points]</code></pre>
<pre class="python"><code>#Quick plot of where commodity deposit data is and generated non-deposit data
ax = plt.axes(projection=ccrs.PlateCarree())
ax.coastlines()
ax.margins(0.05) # 5% padding to the map boundary so we can see the true extent nicely

ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;o&#39;, linestyle=&#39;&#39;, color=&#39;y&#39;)
#ax.plot(lons_rand,lats_rand,marker=&#39;.&#39;,linestyle=&#39;&#39;,color=&#39;k&#39;)
plt.plot(xval,yval,label=&#39;Gawler&#39;)

plt.show()</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_55_0.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="define-function-which-performs-coregisteringdata-mining" class="section level3">
<h3>Define function which performs coregistering/data-mining</h3>
</div>
<div id="run-spatial-mining-of-known-deposits-and-non-deposits" class="section level2">
<h2>Run spatial mining of known deposits and “non-deposits”</h2>
<p>Must be re-run on each commodity change. Can be saved and just loaded in if data has already been generated.</p>
<pre class="python"><code>#Load in co-registerd training data
training_data=pd.read_csv(&quot;ML-DATA/training_data-&quot;+commname+&quot;.csv&quot;,header=0)

#Or if that does not exist run next two cells....</code></pre>
</div>
<div id="run-spatial-mining-of-gawler-target-data" class="section level2">
<h2>Run spatial mining of gawler target data</h2>
<p>Only needs to be done once. Each commodity uses this same dataset for targetting. The values of the grid are used to predict whatever commodity is run. Depending on target resolution and whether using parallel versions, can take a good amount of time.</p>
<pre class="python"><code>#Load in target data
target_data=pd.read_csv(&quot;ML-DATA/target_data.csv&quot;,header=0)

#OR run the next 5 cells....</code></pre>
<pre class="python"><code>################ RUN FROM HERE ONCE (or use the HPC versions for high-res) ##########################
#Make a regularly spaced grid here for use in making a probablilty map later
lats_reg=np.linspace(min(yval),max(yval),10)
lons_reg=np.linspace(min(xval),max(xval),10)
#lats_reg=np.arange(min(yval),max(yval)+0.0100,0.0100)
#lons_reg=np.arange(min(xval),max(xval)+0.0100,0.0100)

sampleData=[]
for lat in lats_reg:
    for lon in lons_reg:
            sampleData.append([lat, lon])
            
print(np.size(sampleData))</code></pre>
<pre class="python"><code>#Run the data-mining/coregistration
gridgawler=[]
tic=time.time()
for geophysparams in sampleData:
    #lazy_result = delayed(coregLoop)(geophysparams)
    lazy_result = coregLoop(geophysparams)
    gridgawler.append(lazy_result)
print(&quot;appended, now running...&quot;)

#c=compute(gridgawler)
toc=time.time()

print(&quot;Time taken:&quot;, toc-tic, &quot; seconds&quot;)</code></pre>
<pre class="python"><code>#Clean up the output file
target_data=pd.DataFrame(np.squeeze(gridgawler),columns=lons+numerical_features+categorical_features)</code></pre>
<pre class="python"><code>#Add the categorical shapefile data
target_data[&#39;geol28&#39;]=target_data.apply(shapeExplore, args=(shapesGeol,recsGeol,1), axis=1)
target_data[&#39;archean27&#39;]=target_data.apply(shapeExplore, args=(shapesArch,recsArch,-1), axis=1)</code></pre>
<pre class="python"><code>#Save out the data, and no need to run the co-registration again.
target_data.to_csv(&quot;target_data.csv&quot;,index=False)

################## RUN TO HERE ONCE #########################</code></pre>
<pre class="python"><code>#Look at the target data
#Should be in the same form as the training data WITHOUT the information of whether it is a deposit or non-deposit.
target_data</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
lon
</th>
<th>
lat
</th>
<th>
res-25
</th>
<th>
res-77
</th>
<th>
res-136
</th>
<th>
res-201
</th>
<th>
res-273
</th>
<th>
res-353
</th>
<th>
res-442
</th>
<th>
res-541
</th>
<th>
…
</th>
<th>
mag20-rtp
</th>
<th>
mag21-tmi
</th>
<th>
rad22-dose
</th>
<th>
rad23-k
</th>
<th>
rad24-th
</th>
<th>
rad25-u
</th>
<th>
grav26
</th>
<th>
archean27
</th>
<th>
geol28
</th>
<th>
random
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
131.000009
</td>
<td>
-32.664987
</td>
<td>
-0.8814
</td>
<td>
-0.8562
</td>
<td>
-0.7231
</td>
<td>
-0.5389
</td>
<td>
-0.3426
</td>
<td>
-0.1523
</td>
<td>
0.0268
</td>
<td>
0.1949
</td>
<td>
…
</td>
<td>
-9999.000000
</td>
<td>
-9999.000000
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.000000
</td>
<td>
14536
</td>
<td>
1002
</td>
<td>
999.0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
131.010009
</td>
<td>
-32.664987
</td>
<td>
-0.8814
</td>
<td>
-0.8562
</td>
<td>
-0.7231
</td>
<td>
-0.5389
</td>
<td>
-0.3426
</td>
<td>
-0.1523
</td>
<td>
0.0268
</td>
<td>
0.1949
</td>
<td>
…
</td>
<td>
-9999.000000
</td>
<td>
-9999.000000
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.000000
</td>
<td>
14536
</td>
<td>
1002
</td>
<td>
999.0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
131.020009
</td>
<td>
-32.664987
</td>
<td>
-0.8814
</td>
<td>
-0.8562
</td>
<td>
-0.7231
</td>
<td>
-0.5389
</td>
<td>
-0.3426
</td>
<td>
-0.1523
</td>
<td>
0.0268
</td>
<td>
0.1949
</td>
<td>
…
</td>
<td>
-9999.000000
</td>
<td>
-9999.000000
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.000000
</td>
<td>
14536
</td>
<td>
1002
</td>
<td>
-999.0
</td>
</tr>
<tr>
<th>
3
</th>
<td>
131.030009
</td>
<td>
-32.664987
</td>
<td>
-0.8814
</td>
<td>
-0.8562
</td>
<td>
-0.7231
</td>
<td>
-0.5389
</td>
<td>
-0.3426
</td>
<td>
-0.1523
</td>
<td>
0.0268
</td>
<td>
0.1949
</td>
<td>
…
</td>
<td>
-9999.000000
</td>
<td>
-9999.000000
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.000000
</td>
<td>
14536
</td>
<td>
1002
</td>
<td>
999.0
</td>
</tr>
<tr>
<th>
4
</th>
<td>
131.040009
</td>
<td>
-32.664987
</td>
<td>
-0.8814
</td>
<td>
-0.8562
</td>
<td>
-0.7231
</td>
<td>
-0.5389
</td>
<td>
-0.3426
</td>
<td>
-0.1523
</td>
<td>
0.0268
</td>
<td>
0.1949
</td>
<td>
…
</td>
<td>
-9999.000000
</td>
<td>
-9999.000000
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.000000
</td>
<td>
14536
</td>
<td>
1002
</td>
<td>
999.0
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
374161
</th>
<td>
137.970009
</td>
<td>
-27.344987
</td>
<td>
1.9917
</td>
<td>
1.9870
</td>
<td>
1.9831
</td>
<td>
1.9793
</td>
<td>
1.9749
</td>
<td>
1.9697
</td>
<td>
1.9647
</td>
<td>
1.9629
</td>
<td>
…
</td>
<td>
60.714424
</td>
<td>
77.071075
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-36.425686
</td>
<td>
14548
</td>
<td>
2030
</td>
<td>
-999.0
</td>
</tr>
<tr>
<th>
374162
</th>
<td>
137.980009
</td>
<td>
-27.344987
</td>
<td>
1.9917
</td>
<td>
1.9870
</td>
<td>
1.9831
</td>
<td>
1.9793
</td>
<td>
1.9749
</td>
<td>
1.9697
</td>
<td>
1.9647
</td>
<td>
1.9629
</td>
<td>
…
</td>
<td>
58.152508
</td>
<td>
72.153748
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-35.383732
</td>
<td>
14548
</td>
<td>
2030
</td>
<td>
-999.0
</td>
</tr>
<tr>
<th>
374163
</th>
<td>
137.990009
</td>
<td>
-27.344987
</td>
<td>
1.9924
</td>
<td>
1.9882
</td>
<td>
1.9849
</td>
<td>
1.9819
</td>
<td>
1.9785
</td>
<td>
1.9746
</td>
<td>
1.9707
</td>
<td>
1.9681
</td>
<td>
…
</td>
<td>
56.024078
</td>
<td>
66.960632
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-34.756775
</td>
<td>
14548
</td>
<td>
2030
</td>
<td>
999.0
</td>
</tr>
<tr>
<th>
374164
</th>
<td>
138.000009
</td>
<td>
-27.344987
</td>
<td>
1.9924
</td>
<td>
1.9882
</td>
<td>
1.9849
</td>
<td>
1.9819
</td>
<td>
1.9785
</td>
<td>
1.9746
</td>
<td>
1.9707
</td>
<td>
1.9681
</td>
<td>
…
</td>
<td>
53.722004
</td>
<td>
61.110107
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-34.204567
</td>
<td>
14548
</td>
<td>
2030
</td>
<td>
999.0
</td>
</tr>
<tr>
<th>
374165
</th>
<td>
138.010009
</td>
<td>
-27.344987
</td>
<td>
1.9924
</td>
<td>
1.9882
</td>
<td>
1.9849
</td>
<td>
1.9819
</td>
<td>
1.9785
</td>
<td>
1.9746
</td>
<td>
1.9707
</td>
<td>
1.9681
</td>
<td>
…
</td>
<td>
51.256954
</td>
<td>
54.969093
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-9999.0
</td>
<td>
-33.568863
</td>
<td>
14548
</td>
<td>
2030
</td>
<td>
999.0
</td>
</tr>
</tbody>
</table>
<p>
374166 rows × 97 columns
</p>
</div>
</div>
</div>
<div id="part-3---machine-learning-model" class="section level1">
<h1>Part 3 - Machine learning model</h1>
<p>Now we have a fully data-mined, coregistered set of geophysical features. Both for training with known information about our deposits classification labels, and also a target set, we can build and apply the Machine Learning model classifier.</p>
<pre class="python"><code>#First, we can check some details about the data. 
#Simple check whether at least MOST of the geophysical parameters have a reasonable value associated with them.
[print(training_data.columns[i],j) for i,j in enumerate(training_data.median())]
#If any of these score -9999.0 it is recommended to remove from that column from analysis
#You can do this, by now &quot;commenting out&quot; the layer in cell 27.</code></pre>
<pre><code>lon 138.24976824878848
lat -31.4234139
res-25 2.0562500000000004
res-77 2.07275
res-136 2.0737
res-201 2.0729
res-273 2.0686
res-353 2.0707
res-442 2.06045
res-541 2.0584
res-650 2.0572999999999997
res-772 2.0549999999999997
res-907 2.0544000000000002
res-1056 2.0513
res-1223 2.05735
res-1407 2.0737
res-1612 2.0917000000000003
res-1839 2.0865
res-2092 2.0808999999999997
res-2372 2.0644
res-2683 2.01925
res-3028 2.0089
res-3411 2.0092999999999996
res-3837 1.9667
res-4309 1.98135
res-4833 1.9901499999999999
res-5414 2.0079000000000002
res-6060 2.1113999999999997
res-6776 2.1632
res-7572 2.252
res-8455 2.3027499999999996
res-9435 2.35195
res-10523 2.4196
res-11730 2.4535
res-13071 2.4711499999999997
res-14559 2.5052
res-16210 2.4838
res-18043 2.4543999999999997
res-20078 2.41535
res-22337 2.3192500000000003
res-24844 2.3199
res-27627 2.33305
res-30716 2.2951
res-34145 2.3369999999999997
res-37951 2.372
res-42175 2.3846499999999997
res-46865 2.4406499999999998
res-52070 2.4587
res-57847 2.45555
res-64261 2.51445
res-71379 2.6096500000000002
res-79281 2.6209
res-88052 2.66555
res-97788 2.6927000000000003
res-108595 2.7203999999999997
res-120590 2.68045
res-133905 2.6466000000000003
res-148685 2.5894500000000003
res-165090 2.5436
res-183300 2.4987500000000002
res-203513 2.4674500000000004
res-225950 2.3987
res-250854 2.3303000000000003
res-278498 2.2708
res-309183 2.1997999999999998
neoFaults 0.0900854008002272
archFaults 0.29892370502523613
gairFaults 1.2047528939475927
aster1-AlOH-cont 1.9861243963241577
aster2-AlOH 1.0791621804237366
aster3-FeOH-cont 1.9664206504821777
aster4-Ferric-cont 1.3717382550239563
aster5-Ferrous-cont 0.788004457950592
aster6-Ferrous-index 0.8526997566223145
aster7-MgOH-comp 0.9859207570552826
aster8-MgOH-cont 1.0112017393112183
aster9-green 1.4036157727241516
aster10-kaolin 0.9091927707195282
aster11-opaque -9999.0
aster12-quartz 0.5054315328598022
aster13-regolith-b3 0.9444536566734314
aster14-regolith-b4 1.2997069358825684
aster15-silica 1.066483736038208
base16 158.21937561035156
dem17 218.34683990478516
dtb18 -9999.0
mag19-2vd -1.4414607676371816e-06
mag20-rtp -111.75115966796875
mag21-tmi -117.75409317016602
rad22-dose 40.579397201538086
rad23-k 0.9994525611400604
rad24-th 8.156786918640137
rad25-u 51.71901512145996
grav26 -17.332341194152832
archean27 19208.0
geol28 15514.0
random 999.0
deposit 0.5





[None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None,
 None]</code></pre>
<div id="ml-classification" class="section level3">
<h3>ML Classification</h3>
<p>This is where the ML classifier is defined. We can substitue our favourite ML technique here, and tune model variables as desired. The default choices are recommended for the Gawler region.</p>
<pre class="python"><code>#Create the &#39;feature vector&#39; and a &#39;target classification vector&#39;
features=training_data[numerical_features+categorical_features]
targets=training_data.deposit

#Create the ML classifier with numerical and categorical data
#Scale, and replace missing values
numeric_transformer = Pipeline(steps=[
    (&#39;imputer&#39;,SimpleImputer(missing_values=-9999., strategy=&#39;median&#39;)),
    (&#39;scaler&#39;, StandardScaler())])

#Encode categorical data and fill missing values with default 0
categorical_transformer = Pipeline(steps=[
    (&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;)),
    (&#39;onehot&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))])

#Combine numerical and categorical data
preprocessor = ColumnTransformer(transformers=[
        (&#39;num&#39;, numeric_transformer, numerical_features),
        (&#39;cat&#39;, categorical_transformer, categorical_features)])

# Append classifier to preprocessing pipeline.
# Now we have a full prediction pipeline.
rf = Pipeline(steps=[(&#39;preprocessor&#39;, preprocessor),
                (&#39;classifier&#39;, RandomForestClassifier(random_state=1))])
</code></pre>
<pre class="python"><code>#You can apply weighting to the model here. 
#We find manual selction (i.e with sound geological reasoning) of deposits is probably more robust 
#than applying arbitrary weighting of class labels. 
#Nevertheless, we can do this if desired by uncommenting and tweaking  the following.

weights=np.ones(len(training_data))
weightcount=0

#Algorithm for setting weight values, point by point
# for i,row in enumerate(training_data[training_data.deposit==1].itertuples()):
#     xloc1=(np.abs(np.array(comm.LONGITUDE) - row.lon).argmin())
#     if comm.loc[xloc1].SIZE_VAL==&quot;Locally Significant&quot;:
#         weights[i]=2
#     elif comm.loc[xloc1].SIZE_VAL==&quot;Significant to SA&quot;:
#         weights[i]=4
#     elif comm.loc[xloc1].SIZE_VAL==&quot;Significant to Australia&quot;:
#         weights[i]=8
#     elif comm.loc[xloc1].SIZE_VAL==&quot;World-wide Significance&quot;:
#         weights[i]=16
#     else:
#         #Else keep the weight at 1
#         weightcount+=1
#         weights[i]=0
#         continue
        

    </code></pre>
<pre class="python"><code>print(&#39;Tranining the Clasifier...&#39;)
rf.fit(features,targets,**{&#39;classifier__sample_weight&#39;: weights})

print(&quot;Done RF. Now scoring...&quot;)
scores = cross_val_score(rf, features,targets, cv=10)

print(&quot;RF 10-fold cross validation Scores:&quot;, scores)
print(&quot;SCORE Mean: %.2f&quot; % np.mean(scores), &quot;STD: %.2f&quot; % np.std(scores), &quot;\n&quot;)

plt.plot(targets.values,&#39;b-&#39;,label=&#39;Target (expected)&#39;)
plt.plot(rf.predict(features),&#39;rx&#39;,label=&#39;Prediction&#39;)
plt.xlabel(&quot;Feature set&quot;)
plt.ylabel(&quot;Target/Prediction&quot;)
plt.legend(loc=7)</code></pre>
<pre><code>Tranining the Clasifier...
Done RF. Now scoring...
RF 10-fold cross validation Scores: [0.95652174 0.86956522 1.         0.86956522 0.91304348 0.91304348
 0.7826087  0.86956522 0.82608696 0.69565217]
SCORE Mean: 0.87 STD: 0.08 






&lt;matplotlib.legend.Legend at 0x7ff04942bd30&gt;</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_72_2.png" alt="" />
<p class="caption">png</p>
</div>
<pre class="python"><code>#Make a plot out the feature scores. 
#These are the important parameters that are correlated with the deposits.

ft_idx=[]
ft_lab=[]
all_idx=[]
all_lab=[]
all_dat=[]
#Just print the significant features above some threshold
for i,lab in enumerate(np.append(numerical_features,rf[&#39;preprocessor&#39;].transformers_[1][1][&#39;onehot&#39;].get_feature_names(categorical_features))):
    all_dat.append([i,lab,rf.steps[1][1].feature_importances_[i]])
    all_lab.append(lab)
    all_idx.append(i)
    if rf.steps[1][1].feature_importances_[i] &gt;1*np.median(rf.steps[1][1].feature_importances_): 
        ft_idx.append(i)
        ft_lab.append(lab)
        </code></pre>
<pre class="python"><code>#And plot all the feature importances
#plt.plot(rf.steps[1][1].feature_importances_)

fig, ax = plt.subplots(figsize=(5,30))

ft_imps=rf.steps[1][1].feature_importances_
y_pos=np.arange(len(ft_imps))
ax.barh(y_pos,ft_imps,align=&#39;center&#39;)

ax.set_yticks(all_idx)
ax.set_yticklabels(all_lab)
ax.yaxis.label.set_color(&#39;red&#39;)
for i in ft_idx:
    ax.get_yticklabels()[i].set_color(&quot;red&quot;)

ax.set_xlabel(&#39;Feature Importance&#39;)

plt.show()

#plt.xticks([0,1,2,3,4,5,7,81,82,83,84,85,86])</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_74_0.png" alt="" />
<p class="caption">png</p>
</div>
<pre class="python"><code>#Chec the probabilities at each of the deposit/non-deposit points
print(&#39;RF...&#39;)
pRF=np.array(rf.predict_proba(features))
print(&quot;Done RF&quot;)

plt.plot(pRF[:,1])</code></pre>
<pre><code>RF...
Done RF





[&lt;matplotlib.lines.Line2D at 0x7ff04905b0b8&gt;]</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_75_2.png" alt="" />
<p class="caption">png</p>
</div>
</div>
<div id="finally-apply-the-model-to-the-grid" class="section level2">
<h2>Finally, apply the model to the grid</h2>
<pre class="python"><code>#Apply the trained ML to our gridded data to determine the probabilities at each of the points
print(&#39;RF...&#39;)
pRF_map=np.array(rf.predict_proba(target_data[numerical_features+categorical_features]))
print(&quot;Done RF&quot;)</code></pre>
<pre><code>RF...
Done RF</code></pre>
<pre class="python"><code>#Create a meshgrid from our xyz list of points
gridX,gridY,gridZ=grid(target_data.lon, target_data.lat,pRF_map[:,1])</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: MatplotlibDeprecationWarning: The griddata function was deprecated in Matplotlib 2.2 and will be removed in 3.1. Use scipy.interpolate.griddata instead.</code></pre>
<pre class="python"><code>#Save the csv grid of targets
targetCu = {&#39;Longitude&#39;: target_data.lon, &#39;Latitude&#39;: target_data.lat, &#39;Prediction&#39;: pRF_map[:,1]}
targetCu=pd.DataFrame(targetCu)
targetCu.to_csv(&#39;Targets-&#39;+commname+&#39;.csv&#39;,header=0,index=False)</code></pre>
<pre class="python"><code>#Plot the final target map
fig = plt.figure(figsize=(10,10),dpi=300)

#Make a map projection to plot on.
ax = plt.axes(projection=ccrs.LambertAzimuthalEqualArea(central_longitude=135.0, central_latitude=-31.0))
       
#Set the extent of interest
img_extent = [min(df.LONGITUDE)+1.5,  max(df.LONGITUDE)-3.0, min(df.LATITUDE)+5,max(df.LATITUDE)-1]
ax.set_extent(img_extent)

#Put down a base map
ax.coastlines(resolution=&#39;10m&#39;, color=&#39;gray&#39;,)
tiler = Stamen(&#39;terrain-background&#39;)
mercator = tiler.crs
ax.add_image(tiler, 6)

#Make the gridlines
gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,
                  linewidth=0.3, color=&#39;gray&#39;, alpha=0.5, linestyle=&#39;-&#39;)
gl.top_labels = False
gl.bottom_labels = True
gl.right_labels = False
gl.left_labels = True
#gl.xlines = False
gl.xlocator = mticker.FixedLocator(list(np.linspace(np.floor(min(df.LONGITUDE))+1,np.ceil(max(df.LONGITUDE))-1,num=5)))
gl.ylocator = mticker.FixedLocator(list(np.linspace(np.floor(min(df.LATITUDE))+1,np.ceil(max(df.LATITUDE))-1,num=5)))
gl.xlocator = mticker.FixedLocator([141,138,135,132,129])
gl.ylocator = mticker.FixedLocator([-38,-34,-31,-28,-26])
#gl.ylocator = mticker.FixedLocator(list(np.linspace(-28,-35,num=3)))
gl.xlabel_style = {&#39;size&#39;: 10, &#39;color&#39;: &#39;gray&#39;}
gl.ylabel_style = {&#39;size&#39;: 10, &#39;color&#39;: &#39;gray&#39;}
#gl.xlabel_style = {&#39;color&#39;: &#39;red&#39;, &#39;weight&#39;: &#39;bold&#39;}
gl.xformatter = LONGITUDE_FORMATTER
gl.yformatter = LATITUDE_FORMATTER

#Create a patch of the gawler region where the data is
path=Path(list(zip(xval, yval)))
patch = PathPatch(path, facecolor=&#39;none&#39;,transform = ccrs.PlateCarree(),linestyle=&#39;--&#39;,linewidth=0.5)
plt.gca().add_patch(patch)

#Plot the main map
im=ax.contourf(gridX,gridY,gridZ,cmap=plt.cm.coolwarm,transform = ccrs.PlateCarree(),vmin=0,vmax=1)
#im = ax.imshow(gridZ, interpolation=&#39;bicubic&#39;, cmap=plt.cm.bwr,
#                origin=&#39;lower&#39;, extent=[np.min(gridX),np.max(gridX),np.min(gridY),np.max(gridY)],
#                clip_path=patch, clip_on=True,zorder=1,transform = ccrs.PlateCarree())
for c in im.collections:
    c.set_clip_path(patch)
    
# l5=ax.scatter(commall.LONGITUDE, commall.LATITUDE, 
#               edgecolor=&#39;k&#39;,s=10,marker=&#39;d&#39;, linewidths=0.5,label=&quot;&quot;,
#               c=&#39;r&#39;,cmap=plt.cm.bwr,vmin=0,vmax=1,zorder=2,transform = ccrs.PlateCarree())

#Add the deposits coloured by their classification score
l4=ax.scatter(training_data.lon[training_data.deposit==0], training_data.lat[training_data.deposit==0],
               edgecolor=&#39;k&#39;,s=20,marker=&#39;s&#39;, linewidths=1,label=&quot;&quot;,
               c=pRF[lendep:,1],cmap=plt.cm.bwr,vmin=0,vmax=1,zorder=3,transform = ccrs.PlateCarree())

l3=ax.scatter(training_data.lon[training_data.deposit==1], training_data.lat[training_data.deposit==1], 
              edgecolor=&#39;k&#39;,s=20,marker=&#39;o&#39;, linewidths=1,label=&quot;&quot;,
              c=pRF[:lendep,1],cmap=plt.cm.bwr,vmin=0,vmax=1,zorder=2,transform = ccrs.PlateCarree())

#Plot the outline of the Gawler region
ax.plot(xval,yval,&#39;k--&#39;,label=&#39;Gawler Target Region&#39;,linewidth=0.2)
ax.plot(0,0,&#39;r.&#39;,label=&#39;Known &#39;+commname+&#39; deposits for training&#39;,zorder=3,transform = ccrs.PlateCarree())
ax.plot(0,0,&#39;b.&#39;,label=&#39;Non-Deposits for training&#39;,zorder=3,transform = ccrs.PlateCarree())
#ax.plot(0,0,&#39;rd&#39;,label=&#39;All other Au deposits (not used for training)&#39;,zorder=3,transform = ccrs.PlateCarree())

# ax.plot(xlons,xlats,&#39;y-&#39;,label=&#39;Central Gawler Au Province&#39;,zorder=3,transform = ccrs.PlateCarree())
# ax.plot(xlons2,xlats2,&#39;g-&#39;,label=&#39;Olympic IOCG Province&#39;,zorder=3,transform = ccrs.PlateCarree())

# ax.plot(xval,yval,&#39;k--&#39;,label=&#39;Gawler Target Region&#39;,linewidth=0.5,zorder=2,transform = ccrs.PlateCarree())

# Add a map title, legend, colorbar
#plt.title(&#39;Known deposits and predictive map for Gawler region, SA&#39;)
ax.legend(loc=2,fontsize=12)
#plt.xlabel(&#39;Longitude&#39;)
#plt.ylabel(&#39;Latitude&#39;)

#Make a Colorbar
# cbaxes = fig.add_axes([0.16, 0.27, 0.25, 0.015])
# cbar = plt.colorbar(l3, cax = cbaxes,orientation=&quot;horizontal&quot;)
# cbar.set_label(commname+&#39; prediction&#39;)

cbaxes = fig.add_axes([0.20, 0.22, 0.1, 0.015])
cbar = plt.colorbar(im, cax = cbaxes,orientation=&quot;horizontal&quot;, ticks=[0.0,0.5,1])
# # #cbar.ax.set_xticklabels([&#39;Medium&#39;,&#39;High&#39;],fontsize=8)
cbar.set_label(commname+&#39; Prediction Score&#39;, labelpad=10,fontsize=12)
cbar.ax.xaxis.set_label_position(&#39;top&#39;)

plt.show()</code></pre>
<pre><code>&lt;urlopen error [Errno -5] No address associated with hostname&gt;
&lt;urlopen error [Errno -5] No address associated with hostname&gt;&lt;urlopen error [Errno -5] No address associated with hostname&gt;
&lt;urlopen error [Errno -5] No address associated with hostname&gt;
&lt;urlopen error [Errno -5] No address associated with hostname&gt;
&lt;urlopen error [Errno -5] No address associated with hostname&gt;</code></pre>
<div class="figure">
<img src="01-build_the_data_files/01-build_the_data_80_1.png" alt="" />
<p class="caption">png</p>
</div>
<pre class="python"><code># Import numpy for array processing
import numpy as np

df[&#39;SIZE_VAL_cat&#39;]=df.SIZE_VAL.astype(&#39;category&#39;).cat.codes
# print(df.SIZE_VAL.astype(&#39;category&#39;).cat.categories)
df.SIZE_VAL_cat.plot.hist()

# Lets categorise each of the mineral occurences. We can use these as our targets
df[&#39;SIZE_VAL_cat&#39;] = np.where(df[&#39;SIZE_VAL&#39;]==&#39;&#39;, 0, df[&#39;SIZE_VAL_cat&#39;])
df[&#39;SIZE_VAL_cat&#39;] = np.where(df[&#39;SIZE_VAL&#39;]==&#39;Low Significance&#39;, 0, df[&#39;SIZE_VAL_cat&#39;])
df[&#39;SIZE_VAL_cat&#39;] = np.where(df[&#39;SIZE_VAL&#39;]==&#39;Locally Significant&#39;, 1, df[&#39;SIZE_VAL_cat&#39;])
df[&#39;SIZE_VAL_cat&#39;] = np.where(df[&#39;SIZE_VAL&#39;]==&#39;Significant to Australia&#39;, 1, df[&#39;SIZE_VAL_cat&#39;])
df[&#39;SIZE_VAL_cat&#39;] = np.where(df[&#39;SIZE_VAL&#39;]==&#39;Significant to SA&#39;, 1, df[&#39;SIZE_VAL_cat&#39;])
df[&#39;SIZE_VAL_cat&#39;] = np.where(df[&#39;SIZE_VAL&#39;]==&#39;World-wide Significance&#39;, 1, df[&#39;SIZE_VAL_cat&#39;])


import matplotlib.pyplot as plt
fig = plt.figure(figsize=(8,8))
ax = plt.axes()
im=ax.scatter(df.LONGITUDE,df.LATITUDE,s=5+df.SIZE_VAL_cat.astype(float)*5,c=df.SIZE_VAL_cat,cmap=&#39;bwr&#39;)
ax.plot(xval,yval,&#39;grey&#39;,linestyle=&#39;--&#39;,linewidth=1,label=&#39;SA&#39;)
#ax.plot(comm.LONGITUDE, comm.LATITUDE, marker=&#39;o&#39;, linestyle=&#39;&#39;,markersize=5, color=&#39;y&#39;,label=commname+&quot; Deposits&quot;)

plt.xlim(128.5,141.5)
plt.ylim(-38.5,-25.5)
plt.legend(loc=3)

cbaxes = fig.add_axes([0.40, 0.18, 0.2, 0.015])
cbar = plt.colorbar(im, cax = cbaxes,orientation=&quot;horizontal&quot;,extend=&#39;neither&#39;)
cbar.set_label(&#39;Mines and Minerals Significance&#39;, labelpad=10)
cbar.ax.xaxis.set_label_position(&#39;top&#39;)
cbar.ax.set_xticklabels([&#39;Low&#39;,&#39;&#39;,&#39;High&#39;],fontsize=8)

plt.show()</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
